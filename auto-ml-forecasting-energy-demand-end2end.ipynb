{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "_**Energy Demand Forecasting**_\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Data](#Data)\n",
    "4. [Train](#Train)\n",
    "5. [Deploy](#Deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this example, we show how AutoML can be used for energy demand forecasting.\n",
    "\n",
    "Make sure you have executed the [configuration](../../../configuration.ipynb) before running this notebook.\n",
    "\n",
    "In this notebook you would see\n",
    "1. Creating an Experiment in an existing Workspace\n",
    "2. Instantiating AutoMLConfig with new task type \"forecasting\" for timeseries data training, and other timeseries related settings: for this dataset we use the basic one: \"time_column_name\" \n",
    "3. Training the Model using local compute\n",
    "4. Exploring the results\n",
    "5. Testing the fitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario\n",
    "This scenario focuses on energy demand forecasting where the __goal is to predict the future load on an energy grid__. It is a critical business operation for companies in the energy sector as operators need to maintain the fine balance between the energy consumed on a grid and the energy supplied to it. \n",
    "\n",
    "Too much power supplied to the grid can result in waste of energy or technical faults. However, if too little power is supplied it can lead to blackouts, leaving customers without power. ypically, grid operators can take short-term decisions to manage energy supply to the grid and keep the load in balance. An accurate short-term forecast of energy demand is therefore essential for the operator to make these decisions with confidence.\n",
    "\n",
    "This scenario details the construction of a machine learning energy demand forecasting solution. _The solution is trained on a public dataset from the New York Independent System Operator (NYISO)_ , which operates the power grid for New York State. \n",
    "The dataset includes hourly power demand data for New York City over a period of five years. An additional dataset containing hourly weather conditions in New York City over the same time period was taken from darksky.net. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As part of the setup you have already created a <b>Workspace</b>. For AutoML you would need to create an <b>Experiment</b>. An <b>Experiment</b> is a named object in a <b>Workspace</b>, which is used to run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "# Squash warning messages for cleaner output in the notebook\n",
    "warnings.showwarning = lambda *args, **kwargs: None\n",
    "\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for the run history container in the workspace\n",
    "experiment_name = 'automl-energydemandforecasting'\n",
    "# project folder\n",
    "project_folder = './sample_projects/automl-local-energydemandforecasting'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Run History Name'] = experiment_name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Read energy demanding data from file, and preview data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nyc_energy.csv\", parse_dates=['timeStamp'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to train and test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['timeStamp'] < '2017-02-01']\n",
    "test = data[data['timeStamp'] >= '2017-02-01']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the test data, we will feed X_test to the fitted model and get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.pop('demand').values\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the train data to train and valid\n",
    "\n",
    "Use one month's data as valid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[train['timeStamp'] < '2017-01-01']\n",
    "X_valid = train[train['timeStamp'] >= '2017-01-01']\n",
    "y_train = X_train.pop('demand').values\n",
    "y_valid = X_valid.pop('demand').values\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Instantiate a AutoMLConfig object. This defines the settings and data used to run the experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|forecasting|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>\n",
    "|**iterations**|Number of iterations. In each iteration, Auto ML trains a specific pipeline on the given data|\n",
    "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
    "|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n",
    "|**y**|(sparse) array-like, shape = [n_samples, ], [n_samples, n_classes]<br>Multi-class targets. An indicator matrix turns on multilabel classification.  This should be an array of integers. |\n",
    "|**X_valid**|Data used to evaluate a model in a iteration. (sparse) array-like, shape = [n_samples, n_features]|\n",
    "|**y_valid**|Data used to evaluate a model in a iteration. (sparse) array-like, shape = [n_samples, ], [n_samples, n_classes]<br>Multi-class targets. An indicator matrix turns on multilabel classification.  This should be an array of integers. |\n",
    "|**path**|Relative path to the project folder.  AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column_name = 'timeStamp'\n",
    "automl_settings = {\n",
    "    \"time_column_name\": time_column_name,\n",
    "}\n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'forecasting',\n",
    "                             debug_log = 'automl_nyc_energy_errors.log',\n",
    "                             primary_metric='normalized_root_mean_squared_error',\n",
    "                             iterations = 10,\n",
    "                             iteration_timeout_minutes = 10,\n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             X_valid = X_valid,\n",
    "                             y_valid = y_valid,\n",
    "                             path=project_folder,\n",
    "                             # model_explainability=True,\n",
    "                             verbosity = logging.INFO,\n",
    "                            **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the submit method on the experiment object and pass the run configuration. For Local runs the execution is synchronous. Depending on the data and number of iterations this can run for while.\n",
    "You will see the currently running iterations printing to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model\n",
    "Below we select the best pipeline from our iterations. The get_output method on automl_classifier returns the best run and the fitted model for the last fit invocation. There are overloads on get_output that allow you to retrieve the best run and fitted model for any logged metric or a particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "fitted_model.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve explanation for best model\n",
    "Model explainability is important to understand the features and their importance. This will retrieve the explainability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl.automlexplainer import explain_model\n",
    "\n",
    "shap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = \\\n",
    "    explain_model(fitted_model, X_train, X_test, best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget for monitoring runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Best Fitted Model\n",
    "\n",
    "Predict on training and test set, and calculate residual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fitted_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Check Data Function to remove the nan values from y_test to avoid error when calculate metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(y_test) != len(y_pred):\n",
    "    raise ValueError(\n",
    "        'the true values and prediction values do not have equal length.')\n",
    "elif len(y_test) == 0:\n",
    "    raise ValueError(\n",
    "        'y_true and y_pred are empty.')\n",
    "\n",
    "# if there is any non-numeric element in the y_true or y_pred,\n",
    "# the ValueError exception will be thrown.\n",
    "y_test_f = np.array(y_test).astype(float)\n",
    "y_pred_f = np.array(y_pred).astype(float)\n",
    "\n",
    "# remove entries both in y_true and y_pred where at least\n",
    "# one element in y_true or y_pred is missing\n",
    "y_test = y_test_f[~(np.isnan(y_test_f) | np.isnan(y_pred_f))]\n",
    "y_pred = y_pred_f[~(np.isnan(y_test_f) | np.isnan(y_pred_f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics for the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[Test Data] \\nRoot Mean squared error: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('mean_absolute_error score: %.2f' % mean_absolute_error(y_test, y_pred))\n",
    "print('R2 score: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Plot outputs\n",
    "test_pred = plt.scatter(y_test, y_pred, color='b')\n",
    "test_test = plt.scatter(y_test, y_test, color='g')\n",
    "plt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "Deploy the model into an Azure Container Instance to enable inferencing on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model\n",
    "Register the best model to the AML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = local_run.register_model(description = 'automated ml model for energy demand forecasting', tags = {'ml': \"Forecasting\", 'type': \"automl\"})\n",
    "print(local_run.model_id) # This will be written to the script file later in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scoring Script\n",
    "This will be used to run the model on new data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score_energy_demand.py\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(model_name = '<<modelid>>') # this name is model.id of model that we want to deploy\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(timestamp,precip,temp):\n",
    "    try:\n",
    "        rawdata = json.dumps({timestamp, precip, temp})\n",
    "        data = json.loads(rawdata)\n",
    "        data_arr = numpy.array(data)\n",
    "        result = model.predict(data_arr)\n",
    "        # result = json.dumps({'timeStamp':timestamp, 'precip':precip, 'temp':temp})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\":result.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a YAML File for the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(ws, experiment_name)\n",
    "ml_run = AutoMLRun(experiment = experiment, run_id = local_run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = ml_run.get_run_sdk_dependencies(iteration = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['azureml-train-automl', 'azureml-sdk', 'azureml-core', 'azureml-webservice-schema','azuremlftk']:\n",
    "    print('{}\\t{}'.format(p, dependencies[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn'], pip_packages=[\"azureml-webservice-schema\", \"azuremlftk\", \"azureml-train-automl\"])\n",
    "print(myenv.serialize_to_string())\n",
    "\n",
    "conda_env_file_name = 'my_conda_env.yml'\n",
    "myenv.save_to_file('.', conda_env_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute the actual version number in the environment file.\n",
    "# This is not strictly needed in this notebook because the model should have been generated using the current SDK version.\n",
    "# However, we include this in case this code is used on an experiment from a previous SDK version.\n",
    "\n",
    "with open(conda_env_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "\n",
    "with open(conda_env_file_name, 'w') as cefw:\n",
    "    cefw.write(content.replace(azureml.core.VERSION, dependencies['azureml-sdk']))\n",
    "\n",
    "# Substitute the actual model id in the script file.\n",
    "\n",
    "script_file_name = 'score_energy_demand.py'\n",
    "\n",
    "with open(script_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "\n",
    "with open(script_file_name, 'w') as cefw:\n",
    "    cefw.write(content.replace('<<modelid>>', local_run.model_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate schema file\n",
    "Schema file is used to define the deployed web service REST API, so it is consumable from \"Swagger enabled\" services, such as Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.webservice_schema.sample_definition import SampleDefinition\n",
    "from azureml.webservice_schema.data_types import DataTypes\n",
    "from azureml.webservice_schema.schema_generation import generate_schema\n",
    "\n",
    "schema_file_name = './schema.json'\n",
    "def run(timestamp,precip,temp):\n",
    "    return \"OK\"\n",
    "\n",
    "import numpy as np\n",
    "generate_schema(run, inputs={\n",
    "    \"timestamp\" : SampleDefinition(DataTypes.STANDARD, '2012-01-01 00:00:00'),\n",
    "    \"precip\" : SampleDefinition(DataTypes.STANDARD, 0.0),\n",
    "    \"temp\" : SampleDefinition(DataTypes.STANDARD, 0.0)}, \n",
    "    filepath=schema_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Docker file to include extra dependencies in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker_steps.dockerfile\n",
    "RUN apt-get update && \\\n",
    "    apt-get upgrade -y && \\\n",
    "    apt-get install -y build-essential gcc g++ python-dev unixodbc unixodbc-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_file_name = \"docker_steps.dockerfile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Container Image\n",
    "The container image will be based on the model and is used to deploy the container instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                 execution_script = script_file_name,\n",
    "                                 docker_file = docker_file_name,\n",
    "                                 schema_file = schema_file_name,\n",
    "                                 conda_file = conda_env_file_name,\n",
    "                                 tags = {'ml': \"Forecasting\", 'type': \"automl\"},\n",
    "                                 description = \"Image for automated ml energy demand forecasting predictions\")\n",
    "\n",
    "image = Image.create(name = \"automlenergyforecasting\",\n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Image as a Web Service on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {'ml': \"Forecasting\", 'type': \"automl\"}, \n",
    "                                               description = 'ACI service for automated ml energy demand forecasting predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = 'automlenergyforecasting'\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "xiaga"
   }
  ],
  "kernelspec": {
   "display_name": "Python (myenv2)",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
